{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1134e85b-08f7-4f47-ac52-36071d62bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, GRU, TimeDistributed, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Parameters\n",
    "input_shape = (128, 128, 3)  # Resize images to 128x128\n",
    "batch_size = 64\n",
    "num_classes = 26\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"Augmented_data/train\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    \"Augmented_data/valid\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "# CNN Model for Image Classification\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_steps=valid_generator.samples // batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcea612-2d55-4210-944b-4d0e23d31aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19986 images belonging to 26 classes.\n",
      "Found 7512 images belonging to 26 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arshi\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.1115 - loss: 3.0347"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arshi\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1332s\u001b[0m 4s/step - accuracy: 0.1115 - loss: 3.0346 - val_accuracy: 0.1333 - val_loss: 2.9155 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m  1/312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:59\u001b[0m 2s/step - accuracy: 0.1250 - loss: 2.8751"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arshi\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 133ms/step - accuracy: 0.1250 - loss: 2.8751 - val_accuracy: 0.0000e+00 - val_loss: 3.2395 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1298s\u001b[0m 4s/step - accuracy: 0.1240 - loss: 2.9538 - val_accuracy: 0.1327 - val_loss: 2.9169 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1094 - loss: 2.8404 - val_accuracy: 0.1667 - val_loss: 3.0802 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m772s\u001b[0m 2s/step - accuracy: 0.1337 - loss: 2.9383 - val_accuracy: 0.1321 - val_loss: 2.9161 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 161ms/step - accuracy: 0.0781 - loss: 2.9142 - val_accuracy: 0.3750 - val_loss: 2.6942 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m676s\u001b[0m 2s/step - accuracy: 0.1352 - loss: 2.9316 - val_accuracy: 0.1329 - val_loss: 2.9124 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1094 - loss: 2.9810 - val_accuracy: 0.1250 - val_loss: 3.0909 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m731s\u001b[0m 2s/step - accuracy: 0.1347 - loss: 2.9351 - val_accuracy: 0.1329 - val_loss: 2.9134 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1094 - loss: 3.0566 - val_accuracy: 0.1250 - val_loss: 2.7790 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m698s\u001b[0m 2s/step - accuracy: 0.1289 - loss: 2.9436 - val_accuracy: 0.1330 - val_loss: 2.9150 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0781 - loss: 2.9565 - val_accuracy: 0.0833 - val_loss: 2.7470 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m700s\u001b[0m 2s/step - accuracy: 0.1346 - loss: 2.9259 - val_accuracy: 0.1327 - val_loss: 2.9179 - learning_rate: 1.2500e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1250 - loss: 2.9638 - val_accuracy: 0.1667 - val_loss: 3.0055 - learning_rate: 1.2500e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1293s\u001b[0m 4s/step - accuracy: 0.1338 - loss: 2.9366 - val_accuracy: 0.1329 - val_loss: 2.9131 - learning_rate: 1.2500e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0625 - loss: 2.7844 - val_accuracy: 0.1250 - val_loss: 2.8367 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m238/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m4:50\u001b[0m 4s/step - accuracy: 0.1286 - loss: 2.9278"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Conv1D, Reshape, BatchNormalization, Activation\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Parameters\n",
    "input_shape = (128, 128, 3)  # Resize images to 128x128\n",
    "batch_size = 64\n",
    "num_classes = 26\n",
    "epochs = 20\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"Augmented_data/train\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    \"Augmented_data/valid\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "# TCNN Model\n",
    "def build_model_with_pretrained(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False, input_shape=input_shape, weights=\"imagenet\"\n",
    "    )\n",
    "    base_model.trainable = False  # Freeze pretrained weights\n",
    "    \n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model_with_pretrained(input_shape, num_classes)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Learning Rate Scheduler and ReduceLROnPlateau\n",
    "lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_steps=valid_generator.samples // batch_size,\n",
    "    callbacks=[lr_reduction],\n",
    ")\n",
    "\n",
    "# Plot Loss and Accuracy\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd0f4a-93bf-483f-87e4-7970708019f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get the true labels and predictions\n",
    "validation_steps = valid_generator.samples // valid_generator.batch_size + 1\n",
    "y_true = valid_generator.classes  # True labels\n",
    "y_pred_probs = model.predict(valid_generator, steps=validation_steps)  # Predicted probabilities\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # Predicted labels\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "class_names = list(valid_generator.class_indices.keys())  # Get class names\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print(\"Classification Report:\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd38b450-b56b-428f-aaa7-da4d40b16f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
